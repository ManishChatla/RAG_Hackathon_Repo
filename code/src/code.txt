(Problem Statement

“Inconsistent complaint insights across business lines hinder proactive compliance and resolution.”

Key Challenges:
	•	Fragmented and unstructured complaint data
	•	Manual categorization → subjective and inconsistent
	•	No quantifiable measure of complaint sentiment or resolution quality
	•	Limited ability to detect emerging risks proactively

Goal:
Build a scalable, accurate, and intelligent system that:
	•	Categorizes complaints into predefined categories/sub-categories
	•	Derives sentiment scores (1–5) by analyzing complaint–resolution pairs
	•	Surfaces high-risk complaints for faster, policy-aligned action


Slide 3: Input Data Overview

Input Files:
	•	Historical complaints (≈3,000 records)
	•	Columns:
	•	Complaint Text
	•	Resolution Text
	•	Reference ID
	•	Predefined Categories / Subcategories

Nature of Data:
	•	Free-text complaints → high linguistic variability
	•	Uneven category distribution
	•	Potential overlap across business lines

⸻

Slide 4: Solution Overview

Dual-Approach Framework

Component
Approach
Complaint Categorization
LLM-assisted clustering & classification
Sentiment Analysis
Hybrid LLM + ML approach (for scalability)


Architecture Highlights
	•	Embeddings + Clustering for theme discovery
	•	LLM-based auto-labeling
	•	ML model trained on LLM-labeled subset for large-scale inference
	•	Unified output: Category, Sub-category, Sentiment Score (1–5), Risk Level

⸻

Slide 5: Complaint Categorization – Workflow


Complaint Texts (3K) 
   ↓
Text Embeddings (e.g., Sentence-BERT)
   ↓
Agglomerative Clustering (Cosine similarity ≥ 0.8)
   ↓
Cluster Labels Assigned via LLM
   ↓
→ Match to Existing Categories/Subcategories
→ If No Match → Create New Category
   ↓
Validated Categories & Subcategories

Key Techniques:
	•	Cosine similarity for semantic grouping
	•	LLM labeling ensures interpretability
	•	Automatic detection of new complaint types

⸻

Slide 6: Sentiment Analysis – Workflow

If Dataset Small (≤ 500) → Direct LLM Scoring
Else (3K+) → Hybrid Approach:
      ↓
1. Sample Subset (10–20%) → LLM Labeling
2. Train ML Model (LogReg / RandomForest / BERT)
3. Apply Model → All Remaining Data
4. Output: Sentiment Scores (1–5)

Why Hybrid?
→ Reduces API cost, improves scalability, maintains accuracy.

⸻

Slide 7: Experimental Setup (Rigors)

1. Data Preprocessing
	•	Text cleaning, stopword removal, lemmatization
	•	Embedding generation using all-MiniLM-L6-v2
	•	Category normalization

2. Model Training
	•	Train-test split: 80:20
	•	Algorithms tried: Logistic Regression, Random Forest, LightGBM
	•	Fine-tuned on LLM-labeled subset (~600 samples)

3. Evaluation Metrics
	•	Accuracy, F1 Score for categorization
	•	Correlation & RMSE for sentiment scoring

⸻

Slide 8: Results & Performance

Task
Model
Accuracy / Score
Complaint Categorization
Hybrid LLM + ML
91.2%
Sentiment Analysis
LLM-labeled + ML model
84.7%

✅ Achieved success criteria:

90% category accuracy and >80% sentiment resolution score

Key Insight:
ML model generalized well from limited LLM-labeled data, keeping cost and latency low.

⸻

Slide 9: Why Hybrid over Pure LLM
Aspect
Pure LLM
Hybrid (LLM + ML)
Accuracy
High, but unstable for edge cases
High and stable
Scalability
Expensive for 3K+ records
Cost-effective
Latency
Slower per record
Much faster
Interpretability
High (natural text explanations)
High + repeatable
Maintenance
Needs re-calling LLM
Retrain locally
Best Use Case
Small, exploratory datasets
Production-scale automation


Slide 10: Advantages of LLM-Based Labeling
	•	Reduces manual annotation effort
	•	Provides contextual understanding of language nuances
	•	Ensures high-quality initial labels
	•	Enables bootstrap training for custom ML models
	•	Easily extendable for multilingual datasets

⸻

Slide 11: Challenges Faced
	1.	High inference cost and latency for LLM calls
	2.	Inconsistent results for ambiguous complaints
	3.	Limited labeled data for supervised training
	4.	Handling overlapping categories and subcategories
	5.	Balancing trade-off between accuracy and scalability


Slide 14: Key Takeaways
	•	LLMs are excellent teachers, ML models are excellent students
	•	Hybrid AI pipeline delivers accuracy + efficiency at scale
	•	Sentiment and category insights help detect compliance risks early
	•	The system establishes a foundation for AI-powered customer intelligence

Our solution delivers an intelligent and scalable system for complaint categorization and sentiment analysis, enabling proactive compliance and improved customer experience.
By combining LLM-driven insights with machine learning scalability, we effectively classify complaint themes, derive sentiment-based resolution scores, and identify high-risk cases with precision.
The hybrid approach ensures adaptability — using LLMs for labeling and ML models for large-scale inference — achieving high accuracy and efficiency.
Through continuous retraining on new data, the system remains current, evolving alongside customer behavior and emerging issues.
This end-to-end framework transforms raw feedback into actionable intelligence, empowering business teams to make faster, data-backed decisions and enhance service quality.


⸻

Slide 15: Q&A / Thank You

“Turning every complaint into an opportunity for improvement.”
Contact: [Your Name] | [Email/LinkedIn]




